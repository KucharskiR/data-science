{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTLDuWhSiXvPsjUFd9Hwev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KucharskiR/data-science/blob/main/LSTM_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WuSMzASeSIkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sieć neuronowa LSTM**\n",
        "\n",
        "Celem tego notebook'a jest zrozumienie podstaw detekcji elementów z obrazu.\n",
        "\n",
        "#### **Spis treści:**\n",
        "1. [Import bibliotek](#a0)\n",
        "2. [Config warstwy LSTM](#a1)\n",
        "3. [Konwersja do odcieni szarości](#a2)\n",
        "4. [Detekcja krawędzi](#a3)\n",
        "5. [Detekcja konturu](#a4)\n",
        "6. [Detekcja prostokąta](#a5)\n",
        "7. [Wyświetlenie znalezionego kształtu](#a6)"
      ],
      "metadata": {
        "id": "9_IXOH1xSAE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a0'></a> Import bibliotek"
      ],
      "metadata": {
        "id": "R8c4m6mdRsCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.initializers import TruncatedNormal\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "np.set_printoptions(precision=12, suppress=True, linewidth=150)\n",
        "pd.options.display.float_format = '{:.6f}'.format\n",
        "# sns.set()   <--- seaborn\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oscxr8yAP1qs",
        "outputId": "79e82fbd-d9dd-4ba9-daf9-710d6bf7f7db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51o6kObaoKAk"
      },
      "outputs": [],
      "source": [
        "# Replace 'your_file.csv' with the actual file path\n",
        "file_path = '49f.csv'\n",
        "file_labels = '49.csv'\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file_name = 'my_data1.csv'\n",
        "\n",
        "# Assuming there are three features in your data\n",
        "num_features = 8\n",
        "num_labels = 2\n",
        "num_samples = 1980\n",
        "timestepsPerSample = 120\n",
        "epochs = 200\n",
        "batch = 60\n",
        "\n",
        "STEPS_PER_EPOCH = num_samples/batch\n",
        "\n",
        "# Read the .csv file and create an array\n",
        "data_strings = np.genfromtxt(file_path, delimiter=';')\n",
        "labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
        "\n",
        "# Convert from strings to float and int\n",
        "X = data_strings.astype(float).reshape((num_samples,timestepsPerSample,num_features))\n",
        "Y = labels_strings.astype(float).reshape((num_samples,num_labels))\n",
        "\n",
        "# splitting the dataset 75% for training and 25% testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "x_train = X_train\n",
        "\n",
        "lst = Sequential() # initializing model\n",
        "\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(units=300, return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "lst.add(Dense(100, activation='relu'))\n",
        "lst.add(Dense(50, activation='relu'))\n",
        "lst.add(Dense(25, activation='relu'))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(num_labels, activation='sigmoid'))\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*100,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "# training the model on training dataset\n",
        "# history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch,validation_split=0.2)\n",
        "history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch)\n",
        "\n",
        "# x_test = np.reshape(X_test, (X_test.shape[0],timestepsPerSample,X_test.shape[1]))\n",
        "x_test = X_test\n",
        "\n",
        "# predicting target attribute on testing dataset\n",
        "predict = lst.predict(x_test)\n",
        "\n",
        "# Set print options to suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Concatenate arrays\n",
        "result = np.hstack((predict, y_test))\n",
        "print(result)\n",
        "\n",
        "test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "\n",
        "# Create a DataFrame from the 2D array\n",
        "df = pd.DataFrame(predict, columns=['Column1', 'Column2'])\n",
        "\n",
        "# Export the DataFrame to CSV with semicolon as the delimiter and avoiding scientific notation\n",
        "df.to_csv(csv_file_name, sep=';', index=False, float_format='%.0f')\n",
        "\n",
        "# Read the CSV file into a DataFrame without header\n",
        "df = pd.read_csv(csv_file_name, sep=';', header=None)\n",
        "\n",
        "# Drop the first row containing data\n",
        "df = df.iloc[1:]\n",
        "\n",
        "# Save the modified DataFrame back to the CSV file without header\n",
        "df.to_csv(csv_file_name, sep=';', index=False, header=False)\n",
        "\n",
        "print(f'CSV file name: {csv_file_name}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Config warstwy LSTM"
      ],
      "metadata": {
        "id": "I_DzN6SnsPXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LstmLayer = LSTM(\n",
        "    units=200,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    seed=None,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    input_shape=(1,2)\n",
        ")"
      ],
      "metadata": {
        "id": "7QkuwFzQPIw5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "msrI6vC5xw3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Budowa modelu"
      ],
      "metadata": {
        "id": "L1dMlQcAxrBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Flatten(input_shape=(28, 28)))\n",
        "# model.add(Dense(units=128, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "model = Sequential()\n",
        "model.add(LstmLayer)\n",
        "model.add(Dense(units=2, activation='softmax')) # <----- output layer\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXUBIQvdsdra",
        "outputId": "f924cbbd-41d0-4a16-b87e-f98ea722a39e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 200)               162400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162802 (635.95 KB)\n",
            "Trainable params: 162802 (635.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics['epoch'] = history.epoch\n",
        "metrics"
      ],
      "metadata": {
        "id": "Id7wOgRSPxgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Ocena modelu LSTM"
      ],
      "metadata": {
        "id": "c8fsX9-1SaXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['accuracy'], name='accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['loss'], name='loss'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_accuracy'], name='val_accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_loss'], name='val_loss'), row=1, col=2)\n",
        "\n",
        "fig.update_xaxes(title_text='epochs')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(width=1000, title='Accuracy and Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2XOExmC-wsQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "DEKIy3Pdwuqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Predykcja na podstawie modelu:\n",
        "\n",
        "\n",
        "\n",
        "1.   **model.evaluate(y_true, y_pred)** - pozwala obliczyć metryki modelu\n",
        "2.   **model.predict_classes()** - pozwala zwrócić odpowiednio przewidziane klasy\n",
        "3.   **model.predict_proba(), model.predict()** - pozwala zwrócić prawdopodobieństwo danej klasy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hZjlGQgPw2-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Hnq1sJrZxPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_cls = model.predict_classes(X_test)\n",
        "predictions_cls = np.argmax(model.predict(X_test), axis=-1)\n",
        "predictions_cls"
      ],
      "metadata": {
        "id": "--gCx91W0Csa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}