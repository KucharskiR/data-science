{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1K/nXVKfWPU9VJbCXA2kB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KucharskiR/data-science/blob/main/LSTM_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WuSMzASeSIkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sieć neuronowa LSTM**\n",
        "\n",
        "Budowa sieci neuronowej LSTM\n",
        "\n",
        "#### **Spis treści:**\n",
        "1. [Import bibliotek](#a0)\n",
        "2. [Przygotowanie danych](#a1)\n",
        "3. [Konfiguracja LSTM layer](#a2)\n",
        "4. [Główny model](#a3)\n",
        "5. [Klasyfikacja](#a4)\n",
        "6. [Przykład budowy modelu z kursu](#a5)\n",
        "7. [Ocena modelu + wykresy](#a6)\n",
        "8. [Predykcja na podstawie modelu](#a7)\n",
        "9. [Zip file](#a8)\n",
        "10. [Extract .tar.gz](#a9)"
      ],
      "metadata": {
        "id": "9_IXOH1xSAE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a0'></a> Import bibliotek"
      ],
      "metadata": {
        "id": "R8c4m6mdRsCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.models import save_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "import os\n",
        "\n",
        "np.set_printoptions(precision=12, suppress=True, linewidth=150)\n",
        "pd.options.display.float_format = '{:.6f}'.format\n",
        "# sns.set()   <--- seaborn\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "id": "oscxr8yAP1qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Przygotowanie danych"
      ],
      "metadata": {
        "id": "SRGMRUlBQdgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_file.csv' with the actual file path\n",
        "file_path = '49f.csv'\n",
        "file_labels = '49.csv'\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file_name = 'my_data1.csv'\n",
        "\n",
        "# Assuming there are three features in your data\n",
        "num_features = 8\n",
        "num_labels = 2\n",
        "num_samples = 1980\n",
        "timestepsPerSample = 120\n",
        "epochs = 1\n",
        "batch = 60\n",
        "\n",
        "STEPS_PER_EPOCH = num_samples/batch\n",
        "\n",
        "# Read the .csv file and create an array\n",
        "data_strings = np.genfromtxt(file_path, delimiter=';')\n",
        "labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
        "\n",
        "# Convert from strings to float and int\n",
        "X = data_strings.astype(float).reshape((-1,timestepsPerSample,num_features))\n",
        "Y = labels_strings.astype(float).reshape((num_samples,num_labels))\n",
        "print(X.shape)\n",
        "\n",
        "# splitting the dataset 75% for training and 25% testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "x_train = X_train"
      ],
      "metadata": {
        "id": "7Nj3hWqDQb-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a4'></a> Konfiguracja LSTM layer"
      ],
      "metadata": {
        "id": "8HqOhfTgQsYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LstmLayer = LSTM(\n",
        "    units=200,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    seed=None,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    input_shape=(x_train.shape[1],x_train.shape[2])\n",
        ")"
      ],
      "metadata": {
        "id": "c_nNj1oIQRZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a3'></a> Główny model"
      ],
      "metadata": {
        "id": "JtbGqmW8Q49l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51o6kObaoKAk"
      },
      "outputs": [],
      "source": [
        "lst = Sequential() # initializing model\n",
        "\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "# lst.add(LSTM(units=300, return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "lst.add(LstmLayer)\n",
        "lst.add(Dense(100, activation='relu'))\n",
        "lst.add(Dense(50, activation='relu'))\n",
        "lst.add(Dense(25, activation='relu'))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(num_labels, activation='sigmoid'))\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*100,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "lst.summary()\n",
        "\n",
        "# training the model on training dataset\n",
        "# history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch,validation_split=0.2)\n",
        "history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save model\n",
        "lst.save(\"lstm_Model.keras\", overwrite=True, save_format='keras',)\n",
        "\n",
        "# x_test = np.reshape(X_test, (X_test.shape[0],timestepsPerSample,X_test.shape[1]))\n",
        "x_test = X_test\n",
        "\n",
        "# predicting target attribute on testing dataset\n",
        "predict = lst.predict(x_test)\n",
        "# predict = np.argmax(lst.predict(x_test), axis=-1)\n",
        "\n",
        "# Set print options to suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Concatenate arrays\n",
        "result = np.hstack((predict, y_test))\n",
        "print(result)\n",
        "\n",
        "test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "\n",
        "# Create a DataFrame from the 2D array\n",
        "df = pd.DataFrame(predict, columns=['Column1', 'Column2'])\n",
        "\n",
        "# Export the DataFrame to CSV with semicolon as the delimiter and avoiding scientific notation\n",
        "# df.to_csv(csv_file_name, sep=';', index=False, float_format='%.0f')\n",
        "df.to_csv(csv_file_name, sep=';', index=False)\n",
        "\n",
        "# Read the CSV file into a DataFrame without header\n",
        "df = pd.read_csv(csv_file_name, sep=';', header=None)\n",
        "\n",
        "# Drop the first row containing data\n",
        "df = df.iloc[1:]\n",
        "\n",
        "# Save the modified DataFrame back to the CSV file without header\n",
        "df.to_csv(csv_file_name, sep=';', index=False, header=False)\n",
        "\n",
        "print(f'CSV file name: {csv_file_name}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a4'></a> Klasyfikacja"
      ],
      "metadata": {
        "id": "Gi3IESNbmXQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.info(predict)\n",
        "# np.where(y_pred > threshold, 1,0)\n",
        "predict_classes = predict\n",
        "# predict_classes = np.argmax(predict_classes, axis=-1)\n",
        "predict_classes = np.where(predict > 0.5, 1,0)\n",
        "np.info(predict_classes)\n",
        "predict_classes\n",
        "# predict"
      ],
      "metadata": {
        "id": "WqQZNp_UhtfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = lst.predict(x_test)\n",
        "predict\n",
        "\n",
        "# # Set print options to suppress scientific notation\n",
        "# np.set_printoptions(suppress=True)\n",
        "\n",
        "# # Concatenate arrays\n",
        "# result = np.hstack((predict, y_test))\n",
        "# print(result)\n",
        "\n",
        "# test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "# print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "QpZVxifpko37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "msrI6vC5xw3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a5'></a> Przykład budowy modelu z kursu"
      ],
      "metadata": {
        "id": "L1dMlQcAxrBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Flatten(input_shape=(28, 28)))\n",
        "# model.add(Dense(units=128, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "model = Sequential()\n",
        "model.add(LstmLayer)\n",
        "model.add(Dense(units=2, activation='softmax')) # <----- output layer\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XXUBIQvdsdra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**epochs** - ile razy zestaw treningowy zostanie przetworzony przez model. Przy każdej iteracji optymalizator próbuje dopasować wagi, aby funkcja celu została zminimalizowana.\n",
        "\n",
        "**batch_size** - liczba przykładów treningowych po której następuje aktualizacji wag\n",
        "\n",
        "**validation_split** - procent danych użytych do walidacji"
      ],
      "metadata": {
        "id": "iP8wBH2x6zN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics['epoch'] = history.epoch\n",
        "metrics"
      ],
      "metadata": {
        "id": "Id7wOgRSPxgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a6'></a> Ocena modelu LSTM"
      ],
      "metadata": {
        "id": "c8fsX9-1SaXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['accuracy'], name='accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['loss'], name='loss'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_accuracy'], name='val_accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_loss'], name='val_loss'), row=1, col=2)\n",
        "\n",
        "fig.update_xaxes(title_text='epochs')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(width=1000, title='Accuracy and Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2XOExmC-wsQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "DEKIy3Pdwuqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a7'></a> Predykcja na podstawie modelu:\n",
        "\n",
        "\n",
        "\n",
        "1.   **model.evaluate(y_true, y_pred)** - pozwala obliczyć metryki modelu\n",
        "2.   **model.predict_classes()** - pozwala zwrócić odpowiednio przewidziane klasy\n",
        "3.   **model.predict_proba(), model.predict()** - pozwala zwrócić prawdopodobieństwo danej klasy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hZjlGQgPw2-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Hnq1sJrZxPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_cls = model.predict_classes(X_test)\n",
        "predictions_cls = np.argmax(model.predict(X_test), axis=-1)\n",
        "predictions_cls"
      ],
      "metadata": {
        "id": "--gCx91W0Csa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics['epoch'] = history.epoch\n",
        "metrics"
      ],
      "metadata": {
        "id": "YLoVcniO6toN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "GLQ4_vcn6oQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('lstm_Model.keras')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VTcKTFtqDz05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a8'></a> Zip file"
      ],
      "metadata": {
        "id": "EOfWIf-3-UsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip = ZipFile('my_python_files.zip','w')\n",
        "zip.write('lstm_Model.keras')"
      ],
      "metadata": {
        "id": "BzXru1KVD_H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a9'></a> Extract tar gz"
      ],
      "metadata": {
        "id": "qwJG5yS6PU-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the \"tarfile\" module\n",
        "import tarfile\n",
        "\n",
        "# open file\n",
        "file = tarfile.open('gfg.tar.gz')\n",
        "\n",
        "# extracting a specific file\n",
        "file.extract('sample.txt', './content')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "vGD-1oYzPE3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVLlJ_ue-zvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}