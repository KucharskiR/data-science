{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5IiuY6XD3G3zILYjIk6A2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KucharskiR/data-science/blob/main/LSTM_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WuSMzASeSIkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sieć neuronowa LSTM**\n",
        "\n",
        "Budowa sieci neuronowej LSTM\n",
        "\n",
        "#### **Spis treści:**\n",
        "1. [Import bibliotek](#a0)\n",
        "2. [Klasyfikacja](#a1)\n",
        "3. [Config warstwy LSTM](#a2)\n",
        "4. [Budowa modelu](#a3)\n",
        "5. [Ocena modelu LSTM](#a4)\n",
        "6. [Predykcja na podstawie modelu](#a5)\n",
        "7. [Zip .keras file](#a6)"
      ],
      "metadata": {
        "id": "9_IXOH1xSAE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a0'></a> Import bibliotek"
      ],
      "metadata": {
        "id": "R8c4m6mdRsCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.models import save_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "import os\n",
        "\n",
        "np.set_printoptions(precision=12, suppress=True, linewidth=150)\n",
        "pd.options.display.float_format = '{:.6f}'.format\n",
        "# sns.set()   <--- seaborn\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oscxr8yAP1qs",
        "outputId": "ae0e37e3-8302-4f7b-ef5c-70e28e40b03a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "51o6kObaoKAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bbc3a0-9fb3-4e27-fde8-24bc17e94c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1980, 120, 8)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 300)               370800    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 2)                 52        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407277 (1.55 MB)\n",
            "Trainable params: 407277 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "27/27 [==============================] - 22s 705ms/step - loss: 0.6545 - accuracy: 0.6269 - val_loss: 0.5840 - val_accuracy: 0.7475\n",
            "13/13 [==============================] - 2s 125ms/step\n",
            "[[0.33159211278  0.686980485916 0.             1.            ]\n",
            " [0.339477658272 0.678693413734 0.             1.            ]\n",
            " [0.363531708717 0.650026321411 0.             1.            ]\n",
            " ...\n",
            " [0.305145174265 0.70778042078  0.             1.            ]\n",
            " [0.303798347712 0.714581549168 0.             1.            ]\n",
            " [0.312339633703 0.708904206753 0.             1.            ]]\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.5840 - accuracy: 0.7475\n",
            "Test results - Loss: 0.5839695930480957 - Accuracy: 74.7474730014801%\n",
            "CSV file name: my_data1.csv.\n"
          ]
        }
      ],
      "source": [
        "# Replace 'your_file.csv' with the actual file path\n",
        "file_path = '49f.csv'\n",
        "file_labels = '49.csv'\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file_name = 'my_data1.csv'\n",
        "\n",
        "# Assuming there are three features in your data\n",
        "num_features = 8\n",
        "num_labels = 2\n",
        "num_samples = 1980\n",
        "timestepsPerSample = 120\n",
        "epochs = 1\n",
        "batch = 60\n",
        "\n",
        "STEPS_PER_EPOCH = num_samples/batch\n",
        "\n",
        "# Read the .csv file and create an array\n",
        "data_strings = np.genfromtxt(file_path, delimiter=';')\n",
        "labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
        "\n",
        "# Convert from strings to float and int\n",
        "X = data_strings.astype(float).reshape((-1,timestepsPerSample,num_features))\n",
        "Y = labels_strings.astype(float).reshape((num_samples,num_labels))\n",
        "print(X.shape)\n",
        "\n",
        "# splitting the dataset 75% for training and 25% testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "x_train = X_train\n",
        "\n",
        "lst = Sequential() # initializing model\n",
        "\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(units=300, return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "lst.add(Dense(100, activation='relu'))\n",
        "lst.add(Dense(50, activation='relu'))\n",
        "lst.add(Dense(25, activation='relu'))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(num_labels, activation='sigmoid'))\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*100,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "lst.summary()\n",
        "\n",
        "# training the model on training dataset\n",
        "# history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch,validation_split=0.2)\n",
        "history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save model\n",
        "lst.save(\"lstm_Model.keras\", overwrite=True, save_format='keras',)\n",
        "\n",
        "# x_test = np.reshape(X_test, (X_test.shape[0],timestepsPerSample,X_test.shape[1]))\n",
        "x_test = X_test\n",
        "\n",
        "# predicting target attribute on testing dataset\n",
        "predict = lst.predict(x_test)\n",
        "# predict = np.argmax(lst.predict(x_test), axis=-1)\n",
        "\n",
        "# Set print options to suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Concatenate arrays\n",
        "result = np.hstack((predict, y_test))\n",
        "print(result)\n",
        "\n",
        "test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "\n",
        "# Create a DataFrame from the 2D array\n",
        "df = pd.DataFrame(predict, columns=['Column1', 'Column2'])\n",
        "\n",
        "# Export the DataFrame to CSV with semicolon as the delimiter and avoiding scientific notation\n",
        "# df.to_csv(csv_file_name, sep=';', index=False, float_format='%.0f')\n",
        "df.to_csv(csv_file_name, sep=';', index=False)\n",
        "\n",
        "# Read the CSV file into a DataFrame without header\n",
        "df = pd.read_csv(csv_file_name, sep=';', header=None)\n",
        "\n",
        "# Drop the first row containing data\n",
        "df = df.iloc[1:]\n",
        "\n",
        "# Save the modified DataFrame back to the CSV file without header\n",
        "df.to_csv(csv_file_name, sep=';', index=False, header=False)\n",
        "\n",
        "print(f'CSV file name: {csv_file_name}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a1'></a> Klasyfikacja"
      ],
      "metadata": {
        "id": "Gi3IESNbmXQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.info(predict)\n",
        "# np.where(y_pred > threshold, 1,0)\n",
        "predict_classes = predict\n",
        "# predict_classes = np.argmax(predict_classes, axis=-1)\n",
        "predict_classes = np.where(predict > 0.5, 1,0)\n",
        "np.info(predict_classes)\n",
        "predict_classes\n",
        "# predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqQZNp_UhtfY",
        "outputId": "8535e523-b036-44c7-bd8d-81e89edf65a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class:  ndarray\n",
            "shape:  (396, 2)\n",
            "strides:  (16, 8)\n",
            "itemsize:  8\n",
            "aligned:  True\n",
            "contiguous:  True\n",
            "fortran:  False\n",
            "data pointer: 0x568c98931310\n",
            "byteorder:  little\n",
            "byteswap:  False\n",
            "type: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = lst.predict(x_test)\n",
        "predict\n",
        "\n",
        "# # Set print options to suppress scientific notation\n",
        "# np.set_printoptions(suppress=True)\n",
        "\n",
        "# # Concatenate arrays\n",
        "# result = np.hstack((predict, y_test))\n",
        "# print(result)\n",
        "\n",
        "# test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "# print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpZVxifpko37",
        "outputId": "9faae9b1-8c16-46ec-abcb-3c0e0caea690"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 64ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7230072  , 0.14410645 ],\n",
              "       [0.66020715 , 0.19439788 ],\n",
              "       [0.7507544  , 0.14352435 ],\n",
              "       [0.747362   , 0.15604775 ],\n",
              "       [0.74823385 , 0.16646087 ],\n",
              "       [0.6466901  , 0.26373684 ],\n",
              "       [0.48162648 , 0.44395354 ],\n",
              "       [0.41195524 , 0.53333294 ],\n",
              "       [0.34093627 , 0.63034254 ],\n",
              "       [0.35216597 , 0.6135457  ],\n",
              "       [0.37822828 , 0.5842517  ],\n",
              "       [0.36576873 , 0.6028791  ],\n",
              "       [0.3380796  , 0.64325106 ],\n",
              "       [0.1716609  , 0.84477055 ],\n",
              "       [0.13796847 , 0.879017   ],\n",
              "       [0.15293995 , 0.8623439  ],\n",
              "       [0.24202456 , 0.763068   ],\n",
              "       [0.3153965  , 0.67032796 ],\n",
              "       [0.2781363  , 0.7176801  ],\n",
              "       [0.26361158 , 0.7325861  ],\n",
              "       [0.23802458 , 0.76176715 ],\n",
              "       [0.25200418 , 0.7441679  ],\n",
              "       [0.24661916 , 0.74938583 ],\n",
              "       [0.24971564 , 0.7456663  ],\n",
              "       [0.26780802 , 0.7248803  ],\n",
              "       [0.27563718 , 0.71667963 ],\n",
              "       [0.45031077 , 0.5021522  ],\n",
              "       [0.67488855 , 0.2734525  ],\n",
              "       [0.76830274 , 0.21579167 ],\n",
              "       [0.74399424 , 0.24361125 ],\n",
              "       [0.5237369  , 0.48257583 ],\n",
              "       [0.3663804  , 0.6461386  ],\n",
              "       [0.26072857 , 0.75596535 ],\n",
              "       [0.22810684 , 0.78997535 ],\n",
              "       [0.17832208 , 0.8390862  ],\n",
              "       [0.1724935  , 0.84480387 ],\n",
              "       [0.1973443  , 0.8226292  ],\n",
              "       [0.3222447  , 0.7027424  ],\n",
              "       [0.2447841  , 0.7793948  ],\n",
              "       [0.20430663 , 0.81973994 ],\n",
              "       [0.22135781 , 0.8015673  ],\n",
              "       [0.4007844  , 0.59702975 ],\n",
              "       [0.49281746 , 0.49295363 ],\n",
              "       [0.89265925 , 0.10276403 ],\n",
              "       [0.9083114  , 0.09538929 ],\n",
              "       [0.9115167  , 0.09473864 ],\n",
              "       [0.89742416 , 0.11012853 ],\n",
              "       [0.8907069  , 0.11760972 ],\n",
              "       [0.88666517 , 0.12232744 ],\n",
              "       [0.88040614 , 0.13202761 ],\n",
              "       [0.84066707 , 0.17824525 ],\n",
              "       [0.7745458  , 0.25271633 ],\n",
              "       [0.75226694 , 0.2699207  ],\n",
              "       [0.6598103  , 0.34605455 ],\n",
              "       [0.39306003 , 0.5806248  ],\n",
              "       [0.2679005  , 0.69923997 ],\n",
              "       [0.21245237 , 0.7522317  ],\n",
              "       [0.16668107 , 0.80505925 ],\n",
              "       [0.16923621 , 0.80181915 ],\n",
              "       [0.13823481 , 0.8386576  ],\n",
              "       [0.12223374 , 0.8620958  ],\n",
              "       [0.11425633 , 0.8752489  ],\n",
              "       [0.14468925 , 0.8414633  ],\n",
              "       [0.19543129 , 0.7880948  ],\n",
              "       [0.39045233 , 0.5703241  ],\n",
              "       [0.7396966  , 0.246905   ],\n",
              "       [0.843746   , 0.15967779 ],\n",
              "       [0.87477934 , 0.12982571 ],\n",
              "       [0.8758938  , 0.1315002  ],\n",
              "       [0.84878826 , 0.16364771 ],\n",
              "       [0.79054034 , 0.22584274 ],\n",
              "       [0.8042077  , 0.2114354  ],\n",
              "       [0.75052476 , 0.25946411 ],\n",
              "       [0.71007127 , 0.29375106 ],\n",
              "       [0.2956878  , 0.6807299  ],\n",
              "       [0.23157384 , 0.75385654 ],\n",
              "       [0.23551835 , 0.73830813 ],\n",
              "       [0.30588198 , 0.65889084 ],\n",
              "       [0.31827068 , 0.64397985 ],\n",
              "       [0.2763079  , 0.6836509  ],\n",
              "       [0.30460393 , 0.65527064 ],\n",
              "       [0.25358722 , 0.70558035 ],\n",
              "       [0.16027993 , 0.8275755  ],\n",
              "       [0.13888696 , 0.85529655 ],\n",
              "       [0.12892336 , 0.87282515 ],\n",
              "       [0.13885029 , 0.8680984  ],\n",
              "       [0.1561144  , 0.85530025 ],\n",
              "       [0.19193448 , 0.8226319  ],\n",
              "       [0.28188932 , 0.7212472  ],\n",
              "       [0.31194305 , 0.70158565 ],\n",
              "       [0.355052   , 0.6636211  ],\n",
              "       [0.37701753 , 0.65010196 ],\n",
              "       [0.41164133 , 0.6119039  ],\n",
              "       [0.48073214 , 0.52620137 ],\n",
              "       [0.57683843 , 0.41735256 ],\n",
              "       [0.6658668  , 0.33474344 ],\n",
              "       [0.64605    , 0.35465512 ],\n",
              "       [0.56413233 , 0.43501794 ],\n",
              "       [0.57175356 , 0.42853385 ],\n",
              "       [0.52725744 , 0.48092526 ],\n",
              "       [0.5330163  , 0.47449806 ],\n",
              "       [0.5194398  , 0.4893039  ],\n",
              "       [0.49889335 , 0.5142749  ],\n",
              "       [0.49459177 , 0.52045816 ],\n",
              "       [0.48656622 , 0.5322927  ],\n",
              "       [0.47961164 , 0.5439554  ],\n",
              "       [0.4659432  , 0.5593024  ],\n",
              "       [0.4574915  , 0.5673927  ],\n",
              "       [0.39014363 , 0.616515   ],\n",
              "       [0.4075289  , 0.60109156 ],\n",
              "       [0.4187699  , 0.5834511  ],\n",
              "       [0.4167644  , 0.5799162  ],\n",
              "       [0.412608   , 0.58400494 ],\n",
              "       [0.3814819  , 0.618796   ],\n",
              "       [0.3596307  , 0.63949823 ],\n",
              "       [0.34901792 , 0.6502086  ],\n",
              "       [0.27491143 , 0.7252101  ],\n",
              "       [0.22252552 , 0.7800441  ],\n",
              "       [0.1844164  , 0.8171755  ],\n",
              "       [0.18520401 , 0.8186208  ],\n",
              "       [0.1948274  , 0.7986202  ],\n",
              "       [0.18520384 , 0.8070986  ],\n",
              "       [0.18464112 , 0.8084538  ],\n",
              "       [0.19934857 , 0.79329044 ],\n",
              "       [0.18935151 , 0.801693   ],\n",
              "       [0.18325755 , 0.80643004 ],\n",
              "       [0.17861763 , 0.81068105 ],\n",
              "       [0.2214628  , 0.7638428  ],\n",
              "       [0.2150598  , 0.7713903  ],\n",
              "       [0.20946488 , 0.7777291  ],\n",
              "       [0.20135398 , 0.78658617 ],\n",
              "       [0.20242544 , 0.7855086  ],\n",
              "       [0.2063853  , 0.78169644 ],\n",
              "       [0.11657197 , 0.89390856 ],\n",
              "       [0.09812014 , 0.9137965  ],\n",
              "       [0.08856144 , 0.92376095 ],\n",
              "       [0.08562365 , 0.9263161  ],\n",
              "       [0.08488567 , 0.9268387  ],\n",
              "       [0.101729445, 0.9061738  ],\n",
              "       [0.11592407 , 0.8888631  ],\n",
              "       [0.182995   , 0.7942781  ],\n",
              "       [0.26808983 , 0.6934201  ],\n",
              "       [0.31357315 , 0.6436238  ],\n",
              "       [0.28053764 , 0.68564326 ],\n",
              "       [0.35170904 , 0.61172426 ],\n",
              "       [0.3751195  , 0.58991176 ],\n",
              "       [0.4416985  , 0.5290301  ],\n",
              "       [0.336574   , 0.636086   ],\n",
              "       [0.2847936  , 0.70112085 ],\n",
              "       [0.29000166 , 0.6964718  ],\n",
              "       [0.33232927 , 0.65081835 ],\n",
              "       [0.4079934  , 0.5730606  ],\n",
              "       [0.4037652  , 0.5824067  ],\n",
              "       [0.34954026 , 0.647596   ],\n",
              "       [0.4035234  , 0.59453547 ],\n",
              "       [0.43660632 , 0.5635805  ],\n",
              "       [0.6317895  , 0.33590582 ],\n",
              "       [0.7377753  , 0.24721137 ],\n",
              "       [0.70213515 , 0.29364043 ],\n",
              "       [0.58471954 , 0.412335   ],\n",
              "       [0.45589685 , 0.5336617  ],\n",
              "       [0.4343673  , 0.5593653  ],\n",
              "       [0.42438036 , 0.56533873 ],\n",
              "       [0.4063652  , 0.5885247  ],\n",
              "       [0.37266085 , 0.6356436  ],\n",
              "       [0.33565378 , 0.6733344  ],\n",
              "       [0.3096663  , 0.70057386 ],\n",
              "       [0.3110496  , 0.7087385  ],\n",
              "       [0.34559026 , 0.6880051  ],\n",
              "       [0.3686671  , 0.66655105 ],\n",
              "       [0.36184266 , 0.6667382  ],\n",
              "       [0.36137488 , 0.66054714 ],\n",
              "       [0.41032043 , 0.59400654 ],\n",
              "       [0.4325111  , 0.55781364 ],\n",
              "       [0.42198372 , 0.564304   ],\n",
              "       [0.4114526  , 0.57133734 ],\n",
              "       [0.41702363 , 0.5626023  ],\n",
              "       [0.40244335 , 0.5785017  ],\n",
              "       [0.33800736 , 0.6590129  ],\n",
              "       [0.32727295 , 0.67227304 ],\n",
              "       [0.33081502 , 0.6700125  ],\n",
              "       [0.3519811  , 0.6492808  ],\n",
              "       [0.30949017 , 0.6995794  ],\n",
              "       [0.28388092 , 0.73060656 ],\n",
              "       [0.2523479  , 0.76714396 ],\n",
              "       [0.2393734  , 0.78127503 ],\n",
              "       [0.21580733 , 0.80473393 ],\n",
              "       [0.20850167 , 0.8115785  ],\n",
              "       [0.19175175 , 0.8279414  ],\n",
              "       [0.19622579 , 0.822079   ],\n",
              "       [0.1951687  , 0.8217104  ],\n",
              "       [0.20445837 , 0.81066674 ],\n",
              "       [0.26350695 , 0.7445513  ],\n",
              "       [0.36515844 , 0.6203535  ],\n",
              "       [0.41596383 , 0.5576877  ],\n",
              "       [0.35949016 , 0.63101244 ],\n",
              "       [0.3663676  , 0.62602264 ],\n",
              "       [0.31458896 , 0.6866329  ],\n",
              "       [0.30345204 , 0.7003623  ],\n",
              "       [0.29887342 , 0.7072576  ],\n",
              "       [0.28827175 , 0.7204131  ],\n",
              "       [0.28140986 , 0.72912306 ],\n",
              "       [0.29008552 , 0.7209737  ],\n",
              "       [0.33069694 , 0.6747388  ],\n",
              "       [0.3024736  , 0.70865434 ],\n",
              "       [0.3050548  , 0.7063949  ],\n",
              "       [0.3508271  , 0.65447176 ],\n",
              "       [0.30886596 , 0.70296985 ],\n",
              "       [0.32580602 , 0.68419737 ],\n",
              "       [0.35763234 , 0.6486954  ],\n",
              "       [0.34799674 , 0.66055584 ],\n",
              "       [0.36646187 , 0.6402839  ],\n",
              "       [0.42952204 , 0.5609638  ],\n",
              "       [0.5280433  , 0.45229724 ],\n",
              "       [0.6071849  , 0.3701719  ],\n",
              "       [0.7682406  , 0.21830435 ],\n",
              "       [0.77471745 , 0.2262097  ],\n",
              "       [0.60508186 , 0.38792092 ],\n",
              "       [0.49598867 , 0.5084572  ],\n",
              "       [0.47510257 , 0.5347707  ],\n",
              "       [0.44547486 , 0.5627091  ],\n",
              "       [0.42253327 , 0.57969075 ],\n",
              "       [0.4187851  , 0.5890353  ],\n",
              "       [0.41108286 , 0.5993309  ],\n",
              "       [0.4044424  , 0.6123527  ],\n",
              "       [0.39871046 , 0.6234772  ],\n",
              "       [0.36725038 , 0.6408773  ],\n",
              "       [0.34980488 , 0.66610926 ],\n",
              "       [0.3262345  , 0.71048844 ],\n",
              "       [0.27512175 , 0.75934565 ],\n",
              "       [0.20164016 , 0.82121074 ],\n",
              "       [0.12551032 , 0.89278024 ],\n",
              "       [0.08000895 , 0.92641544 ],\n",
              "       [0.05949506 , 0.9381254  ],\n",
              "       [0.054880034, 0.9422919  ],\n",
              "       [0.07389648 , 0.9271975  ],\n",
              "       [0.1261044  , 0.86981434 ],\n",
              "       [0.25632223 , 0.68533164 ],\n",
              "       [0.24029219 , 0.6898442  ],\n",
              "       [0.26292977 , 0.641744   ],\n",
              "       [0.2215195  , 0.72900134 ],\n",
              "       [0.25298327 , 0.69272655 ],\n",
              "       [0.2523886  , 0.7035921  ],\n",
              "       [0.23357527 , 0.73136616 ],\n",
              "       [0.27015808 , 0.68961287 ],\n",
              "       [0.3638722  , 0.56962335 ],\n",
              "       [0.45955327 , 0.4547369  ],\n",
              "       [0.5902608  , 0.3252022  ],\n",
              "       [0.60641617 , 0.33142528 ],\n",
              "       [0.6058208  , 0.34550893 ],\n",
              "       [0.562517   , 0.39982197 ],\n",
              "       [0.47152606 , 0.51137584 ],\n",
              "       [0.41982466 , 0.58079964 ],\n",
              "       [0.48517877 , 0.51056933 ],\n",
              "       [0.59115005 , 0.40404698 ],\n",
              "       [0.7028107  , 0.2861222  ],\n",
              "       [0.45421398 , 0.56219953 ],\n",
              "       [0.3130659  , 0.7061534  ],\n",
              "       [0.26439807 , 0.7575589  ],\n",
              "       [0.22927834 , 0.7909229  ],\n",
              "       [0.19282928 , 0.82515645 ],\n",
              "       [0.19399731 , 0.82431686 ],\n",
              "       [0.20435482 , 0.8158293  ],\n",
              "       [0.2228734  , 0.7976027  ],\n",
              "       [0.32767445 , 0.67702675 ],\n",
              "       [0.44950676 , 0.5283333  ],\n",
              "       [0.51176447 , 0.4546401  ],\n",
              "       [0.40629587 , 0.5783454  ],\n",
              "       [0.3734982  , 0.62416434 ],\n",
              "       [0.32762536 , 0.6795966  ],\n",
              "       [0.30408102 , 0.7081269  ],\n",
              "       [0.30111617 , 0.71247613 ],\n",
              "       [0.28211558 , 0.7329657  ],\n",
              "       [0.27709642 , 0.73858476 ],\n",
              "       [0.2628276  , 0.7535687  ],\n",
              "       [0.2851989  , 0.7304238  ],\n",
              "       [0.27529272 , 0.74090856 ],\n",
              "       [0.38369426 , 0.61460894 ],\n",
              "       [0.40816692 , 0.5868927  ],\n",
              "       [0.32740209 , 0.68574214 ],\n",
              "       [0.31484035 , 0.7005166  ],\n",
              "       [0.39329964 , 0.6105637  ],\n",
              "       [0.6218402  , 0.35543576 ],\n",
              "       [0.6701685  , 0.3026982  ],\n",
              "       [0.8426294  , 0.15863368 ],\n",
              "       [0.78942734 , 0.21138838 ],\n",
              "       [0.5566327  , 0.45556387 ],\n",
              "       [0.6786279  , 0.31861755 ],\n",
              "       [0.7252816  , 0.28163046 ],\n",
              "       [0.68842506 , 0.317916   ],\n",
              "       [0.4777706  , 0.51729184 ],\n",
              "       [0.3845153  , 0.60444057 ],\n",
              "       [0.31094396 , 0.69764847 ],\n",
              "       [0.26139668 , 0.75273764 ],\n",
              "       [0.22122528 , 0.78885883 ],\n",
              "       [0.1867892  , 0.8202192  ],\n",
              "       [0.372412   , 0.6542277  ],\n",
              "       [0.5924639  , 0.41374922 ],\n",
              "       [0.67248976 , 0.31256416 ],\n",
              "       [0.52804905 , 0.46578392 ],\n",
              "       [0.346673   , 0.6637896  ],\n",
              "       [0.30651894 , 0.69965917 ],\n",
              "       [0.3099681  , 0.68473786 ],\n",
              "       [0.5013424  , 0.44882873 ],\n",
              "       [0.43296164 , 0.5243909  ],\n",
              "       [0.37736297 , 0.5856445  ],\n",
              "       [0.26613483 , 0.7360415  ],\n",
              "       [0.26021406 , 0.74089247 ],\n",
              "       [0.26894048 , 0.7252611  ],\n",
              "       [0.29849818 , 0.68526137 ],\n",
              "       [0.33496478 , 0.6364031  ],\n",
              "       [0.3284776  , 0.64794683 ],\n",
              "       [0.33577725 , 0.63847244 ],\n",
              "       [0.3487065  , 0.6228826  ],\n",
              "       [0.47959468 , 0.45183548 ],\n",
              "       [0.5643694  , 0.36521953 ],\n",
              "       [0.47448218 , 0.47417554 ],\n",
              "       [0.39289546 , 0.5841484  ],\n",
              "       [0.3796993  , 0.6026426  ],\n",
              "       [0.47051874 , 0.48748118 ],\n",
              "       [0.5366449  , 0.4208625  ],\n",
              "       [0.65399206 , 0.31117678 ],\n",
              "       [0.70234716 , 0.26953033 ],\n",
              "       [0.6682076  , 0.31364688 ],\n",
              "       [0.7820019  , 0.22050567 ],\n",
              "       [0.7965413  , 0.21203709 ],\n",
              "       [0.79445434 , 0.21651776 ],\n",
              "       [0.74644846 , 0.26453522 ],\n",
              "       [0.82884395 , 0.18218984 ],\n",
              "       [0.8301386  , 0.18253563 ],\n",
              "       [0.8585172  , 0.15398376 ],\n",
              "       [0.8175949  , 0.2009875  ],\n",
              "       [0.77706325 , 0.25182086 ],\n",
              "       [0.71564084 , 0.3110709  ],\n",
              "       [0.678549   , 0.3385581  ],\n",
              "       [0.6204421  , 0.39487278 ],\n",
              "       [0.6029693  , 0.4130124  ],\n",
              "       [0.3223289  , 0.6441397  ],\n",
              "       [0.41692746 , 0.5627686  ],\n",
              "       [0.43098146 , 0.54866886 ],\n",
              "       [0.3571179  , 0.6068808  ],\n",
              "       [0.28995088 , 0.66635966 ],\n",
              "       [0.21839981 , 0.7378057  ],\n",
              "       [0.18027674 , 0.7805419  ],\n",
              "       [0.10586817 , 0.8713787  ],\n",
              "       [0.11488544 , 0.86240226 ],\n",
              "       [0.15264446 , 0.8099674  ],\n",
              "       [0.18089038 , 0.7779366  ],\n",
              "       [0.110315986, 0.8711919  ],\n",
              "       [0.08382553 , 0.9107225  ],\n",
              "       [0.08960825 , 0.9086803  ],\n",
              "       [0.13091552 , 0.8624964  ],\n",
              "       [0.14994434 , 0.8494163  ],\n",
              "       [0.19004042 , 0.81358165 ],\n",
              "       [0.4156359  , 0.5632092  ],\n",
              "       [0.53292376 , 0.4465718  ],\n",
              "       [0.4439999  , 0.5590972  ],\n",
              "       [0.42528906 , 0.5964367  ],\n",
              "       [0.43321607 , 0.59468323 ],\n",
              "       [0.44417024 , 0.583511   ],\n",
              "       [0.4617385  , 0.5566175  ],\n",
              "       [0.47506052 , 0.5406099  ],\n",
              "       [0.48021808 , 0.53595585 ],\n",
              "       [0.48569426 , 0.53061193 ],\n",
              "       [0.47037575 , 0.54581064 ],\n",
              "       [0.44059035 , 0.5830148  ],\n",
              "       [0.42390892 , 0.59680754 ],\n",
              "       [0.3769678  , 0.6390345  ],\n",
              "       [0.34644112 , 0.661717   ],\n",
              "       [0.32883194 , 0.6785502  ],\n",
              "       [0.31614643 , 0.6847319  ],\n",
              "       [0.30731836 , 0.687829   ],\n",
              "       [0.266984   , 0.72925544 ],\n",
              "       [0.19284587 , 0.8146461  ],\n",
              "       [0.16522683 , 0.8436096  ],\n",
              "       [0.17049973 , 0.83093774 ],\n",
              "       [0.19017296 , 0.7999175  ],\n",
              "       [0.20873813 , 0.7695975  ],\n",
              "       [0.2277334  , 0.7415074  ],\n",
              "       [0.25098875 , 0.71013165 ],\n",
              "       [0.22925356 , 0.73779106 ],\n",
              "       [0.2066721  , 0.7736511  ],\n",
              "       [0.189507   , 0.8035163  ],\n",
              "       [0.17771223 , 0.82069033 ],\n",
              "       [0.17139375 , 0.8286272  ],\n",
              "       [0.16644092 , 0.83481497 ],\n",
              "       [0.15641975 , 0.8482493  ],\n",
              "       [0.16970704 , 0.8285838  ],\n",
              "       [0.2248164  , 0.75611025 ],\n",
              "       [0.27438632 , 0.6954857  ],\n",
              "       [0.33636242 , 0.62405264 ],\n",
              "       [0.32328057 , 0.64534074 ],\n",
              "       [0.3118229  , 0.66589487 ],\n",
              "       [0.26285756 , 0.7282162  ],\n",
              "       [0.2387843  , 0.7584846  ],\n",
              "       [0.25527185 , 0.73696417 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a2'></a> Config warstwy LSTM"
      ],
      "metadata": {
        "id": "I_DzN6SnsPXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LstmLayer = LSTM(\n",
        "    units=200,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    seed=None,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    input_shape=(1,2)\n",
        ")"
      ],
      "metadata": {
        "id": "7QkuwFzQPIw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "msrI6vC5xw3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a3'></a> Budowa modelu"
      ],
      "metadata": {
        "id": "L1dMlQcAxrBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Flatten(input_shape=(28, 28)))\n",
        "# model.add(Dense(units=128, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "model = Sequential()\n",
        "model.add(LstmLayer)\n",
        "model.add(Dense(units=2, activation='softmax')) # <----- output layer\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXUBIQvdsdra",
        "outputId": "f924cbbd-41d0-4a16-b87e-f98ea722a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 200)               162400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162802 (635.95 KB)\n",
            "Trainable params: 162802 (635.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**epochs** - ile razy zestaw treningowy zostanie przetworzony przez model. Przy każdej iteracji optymalizator próbuje dopasować wagi, aby funkcja celu została zminimalizowana.\n",
        "\n",
        "**batch_size** - liczba przykładów treningowych po której następuje aktualizacji wag\n",
        "\n",
        "**validation_split** - procent danych użytych do walidacji"
      ],
      "metadata": {
        "id": "iP8wBH2x6zN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics['epoch'] = history.epoch\n",
        "metrics"
      ],
      "metadata": {
        "id": "Id7wOgRSPxgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a4'></a> Ocena modelu LSTM"
      ],
      "metadata": {
        "id": "c8fsX9-1SaXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['accuracy'], name='accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['loss'], name='loss'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_accuracy'], name='val_accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=metrics['epoch'], y=metrics['val_loss'], name='val_loss'), row=1, col=2)\n",
        "\n",
        "fig.update_xaxes(title_text='epochs')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(width=1000, title='Accuracy and Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2XOExmC-wsQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "DEKIy3Pdwuqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a5'></a> Predykcja na podstawie modelu:\n",
        "\n",
        "\n",
        "\n",
        "1.   **model.evaluate(y_true, y_pred)** - pozwala obliczyć metryki modelu\n",
        "2.   **model.predict_classes()** - pozwala zwrócić odpowiednio przewidziane klasy\n",
        "3.   **model.predict_proba(), model.predict()** - pozwala zwrócić prawdopodobieństwo danej klasy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hZjlGQgPw2-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Hnq1sJrZxPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_cls = model.predict_classes(X_test)\n",
        "predictions_cls = np.argmax(model.predict(X_test), axis=-1)\n",
        "predictions_cls"
      ],
      "metadata": {
        "id": "--gCx91W0Csa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics['epoch'] = history.epoch\n",
        "metrics"
      ],
      "metadata": {
        "id": "YLoVcniO6toN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "GLQ4_vcn6oQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('lstm_Model.keras')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTcKTFtqDz05",
        "outputId": "10e50245-1063-43cd-bce2-fdef6438f717"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 300)               370800    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 52        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407277 (1.55 MB)\n",
            "Trainable params: 407277 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <a name='a6'></a> Zip .keras file"
      ],
      "metadata": {
        "id": "EOfWIf-3-UsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip = ZipFile('my_python_files.zip','w')\n",
        "zip.write('lstm_Model.keras')"
      ],
      "metadata": {
        "id": "BzXru1KVD_H9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVLlJ_ue-zvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}