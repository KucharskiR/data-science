{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbKrBDqxqUHzmO8Ucv8pQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KucharskiR/data-science/blob/main/LSTM_v_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.initializers import TruncatedNormal\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "oscxr8yAP1qs",
        "outputId": "7e3cfc81-79aa-4655-8c0d-6d4c8424e9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51o6kObaoKAk"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.initializers import TruncatedNormal\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "# Replace 'your_file.csv' with the actual file path\n",
        "file_path = '49f.csv'\n",
        "file_labels = '49.csv'\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file_name = 'my_data1.csv'\n",
        "\n",
        "# Assuming there are three features in your data\n",
        "num_features = 8\n",
        "num_labels = 2\n",
        "num_samples = 1980\n",
        "timestepsPerSample = 120\n",
        "epochs = 200\n",
        "batch = 60\n",
        "\n",
        "STEPS_PER_EPOCH = num_samples/batch\n",
        "\n",
        "# Read the .csv file and create an array\n",
        "data_strings = np.genfromtxt(file_path, delimiter=';')\n",
        "labels_strings = np.genfromtxt(file_labels,delimiter=';')\n",
        "\n",
        "# Convert from strings to float and int\n",
        "X = data_strings.astype(float).reshape((num_samples,timestepsPerSample,num_features))\n",
        "Y = labels_strings.astype(float).reshape((num_samples,num_labels))\n",
        "\n",
        "# splitting the dataset 75% for training and 25% testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "x_train = X_train\n",
        "\n",
        "lst = Sequential() # initializing model\n",
        "\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(units=300, return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "lst.add(Dense(100, activation='relu'))\n",
        "lst.add(Dense(50, activation='relu'))\n",
        "lst.add(Dense(25, activation='relu'))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(num_labels, activation='sigmoid'))\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*100,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "# training the model on training dataset\n",
        "# history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch,validation_split=0.2)\n",
        "history = lst.fit(x_train, y_train, epochs=epochs, batch_size=batch)\n",
        "\n",
        "# x_test = np.reshape(X_test, (X_test.shape[0],timestepsPerSample,X_test.shape[1]))\n",
        "x_test = X_test\n",
        "\n",
        "# predicting target attribute on testing dataset\n",
        "predict = lst.predict(x_test)\n",
        "\n",
        "# Set print options to suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Concatenate arrays\n",
        "result = np.hstack((predict, y_test))\n",
        "print(result)\n",
        "\n",
        "test_results = lst.evaluate(x_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "\n",
        "# Create a DataFrame from the 2D array\n",
        "df = pd.DataFrame(predict, columns=['Column1', 'Column2'])\n",
        "\n",
        "# Export the DataFrame to CSV with semicolon as the delimiter and avoiding scientific notation\n",
        "df.to_csv(csv_file_name, sep=';', index=False, float_format='%.0f')\n",
        "\n",
        "# Read the CSV file into a DataFrame without header\n",
        "df = pd.read_csv(csv_file_name, sep=';', header=None)\n",
        "\n",
        "# Drop the first row containing data\n",
        "df = df.iloc[1:]\n",
        "\n",
        "# Save the modified DataFrame back to the CSV file without header\n",
        "df.to_csv(csv_file_name, sep=';', index=False, header=False)\n",
        "\n",
        "print(f'CSV file name: {csv_file_name}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LstmLayer = LSTM(\n",
        "    units=200,\n",
        "    activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\",\n",
        "    use_bias=True,\n",
        "    kernel_initializer=\"glorot_uniform\",\n",
        "    recurrent_initializer=\"orthogonal\",\n",
        "    bias_initializer=\"zeros\",\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    seed=None,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        ")"
      ],
      "metadata": {
        "id": "7QkuwFzQPIw5",
        "outputId": "90617a53-21e6-4309-9c56-7f8bc43a123f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Layer.count_params of <keras.src.layers.rnn.lstm.LSTM object at 0x7b391dd56ce0>>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Id7wOgRSPxgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}